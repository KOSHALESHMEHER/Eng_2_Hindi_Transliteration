{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enc_Deco_Eng_2_Hindi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOSHALESHMEHER/Eng_2_Hindi_Transliteration/blob/master/Enc_Deco_Eng_2_Hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Data loading\n",
        "4. Data Visualization\n",
        "5. Training\n",
        "6. Loss\n",
        "7. Output\n",
        "8. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd",
        "colab_type": "text"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM",
        "colab_type": "text"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab_type": "code",
        "outputId": "ed736d13-22b8-427e-eac9-05a748b89625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab_type": "code",
        "outputId": "5a943de6-64b4-4602-894c-bf44ffe98f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-",
        "colab_type": "code",
        "outputId": "de9a587c-fdc7-4b72-b11c-ffe5906195cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez",
        "colab_type": "text"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab_type": "code",
        "outputId": "b1b7282e-249e-45a9-893b-11b0ced9b6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "BISHAKHA - बिशाखा\n",
            "EDMONTON - एडमॉन्टन\n",
            "JAI - जय\n",
            "DHEENA - धीना\n",
            "KANAD - कानद\n",
            "HUGHES - ह्युजे\n",
            "DAWSON - डॉसन\n",
            "ROOP - रूप\n",
            "ASIA - आसिया\n",
            "PEDRO - पेड्रो\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab_type": "code",
        "outputId": "e097f6da-96de-408b-a56f-eedc1c315880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MILEK tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab_type": "code",
        "outputId": "5897bb01-9124-4ce0-fa28-bfa20b2b7aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "मिलेक tensor([[47],\n",
            "        [64],\n",
            "        [51],\n",
            "        [72],\n",
            "        [22],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4OgdZ_DVVC5",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8ffT3w4lkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4lyV7xGibU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39uY6Iq_IMKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(net, input, max_length, device = 'cpu'):\n",
        "\n",
        "  input_rep = word_rep(input, eng_alpha2index).to(device)\n",
        "\n",
        "  outputs = net(input=input_rep)\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "88c08ac9-f04b-49ad-e26e-35bb70c734b7",
        "id": "0Pgjjf-qGwgR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "out = infer(net, 'INDIA',30)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_pdzBmQOsjO",
        "colab_type": "code",
        "outputId": "98d1c460-61cd-46cc-de88-865de40bc1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n",
            "torch.Size([1, 129]) ॺ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEg49N9e7oTY",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder(using GRU) with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-1QDAz8F_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMD3zjdJO0Oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoiQwbntO5UH",
        "colab_type": "code",
        "outputId": "b4b9c54c-9af1-41c8-f617-2a0e4ce6dab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9WSPgzlO6k8",
        "colab_type": "code",
        "outputId": "3bfacd25-bdbc-4b6f-a545-4ee3c200856e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) उ\n",
            "torch.Size([1, 129]) उ\n",
            "torch.Size([1, 129]) उ\n",
            "torch.Size([1, 129]) ॕ\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H893cimDtTUE",
        "colab_type": "text"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eZaBxstWz9",
        "colab_type": "text"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY6RvqLtdX8",
        "colab_type": "text"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net1 = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index),verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU",
        "colab_type": "code",
        "outputId": "7b8bc6a4-a41e-42f5-a2c4-9b8239bbef96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        }
      },
      "source": [
        "train_setup(net1, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = 'cpu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 99 Loss 0.2949308454990387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.49927261, 0.48752934, 0.44507805, 0.42702585,\n",
              "       0.41259971, 0.40448728, 0.39601746, 0.39004156, 0.38460726,\n",
              "       0.38240582, 0.37865132, 0.37392867, 0.37072453, 0.3697814 ,\n",
              "       0.36775026, 0.36417526, 0.36091372, 0.35804859, 0.35586384,\n",
              "       0.35510573, 0.35366264, 0.35156676, 0.34888181, 0.34637263,\n",
              "       0.34471351, 0.34390938, 0.34196553, 0.34028026, 0.33829218,\n",
              "       0.33653268, 0.33451968, 0.33325699, 0.33102775, 0.33067045,\n",
              "       0.3295933 , 0.329254  , 0.33058491, 0.33015734, 0.33005825,\n",
              "       0.33006719, 0.3300724 , 0.33003587, 0.32951558, 0.32936156,\n",
              "       0.32885784, 0.32820809, 0.32795045, 0.32748133, 0.32641947,\n",
              "       0.32552868, 0.32498151, 0.32446611, 0.32356244, 0.32277775,\n",
              "       0.32157916, 0.32142857, 0.32124051, 0.32032543, 0.32009572,\n",
              "       0.31928721, 0.31895676, 0.31872311, 0.31801692, 0.31759968,\n",
              "       0.31695843, 0.31629884, 0.31576279, 0.31498128, 0.31455222,\n",
              "       0.31380677, 0.31334096, 0.31226987, 0.31170025, 0.31094751,\n",
              "       0.31040663, 0.30944949, 0.30892581, 0.30807   , 0.30727199,\n",
              "       0.30635989, 0.30573356, 0.30517974, 0.30481309, 0.30413479,\n",
              "       0.30338064, 0.30287367, 0.3023338 , 0.30144158, 0.30084467,\n",
              "       0.30026862, 0.29975787, 0.29908109, 0.29806474, 0.29755551,\n",
              "       0.29694813, 0.29640272, 0.29587471, 0.29553005, 0.29493085,\n",
              "       0.29401314])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bCM-EXNxinF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = infer(net1, 'AJAYA',30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4cnwwgyxr_1",
        "colab_type": "code",
        "outputId": "02d0c1d1-7005-4d98-81dc-1748affc859c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) आ\n",
            "torch.Size([1, 129]) न\n",
            "torch.Size([1, 129]) ा\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Tj20omMi1",
        "colab_type": "text"
      },
      "source": [
        "### Training with Attention "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "colab_type": "code",
        "outputId": "0c67f672-2039-4462-f73f-4a9dae26aba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.01, n_batches=1000, batch_size = 64, display_freq=10, device = 'cpu')"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 999 Loss 0.11678694188594818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder_Attention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7GW1OhU1jjG",
        "colab": {}
      },
      "source": [
        "out = infer(net_att, 'INDIA', 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxBDt6Wz1LWu",
        "colab_type": "code",
        "outputId": "ae62eb6f-c6d9-43c8-a7b8-99d4dbf1e063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(10):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([1, 129]) इ\n",
            "torch.Size([1, 129]) ं\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ि\n",
            "torch.Size([1, 129]) य\n",
            "torch.Size([1, 129]) ा\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) -PAD-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIoeN6WpdszV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef58a867-83cd-4d55-ffd2-b70763251685"
      },
      "source": [
        "def infer(net, word, char_limit, device = 'cpu'):\n",
        "    input = word_rep(word, eng_alpha2index, device)\n",
        "    return net(input, char_limit)\n",
        "\n",
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output\n",
        "\n",
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy\n",
        "\n",
        "# hindi_word = test(net2, 'HELLO')\n",
        "\n",
        "accuracy = calc_accuracy(net_att) * 100\n",
        "print('Accuracy: ', accuracy)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  68.14788517038517\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}